{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3604672",
   "metadata": {},
   "source": [
    "# TEAM NAME: Classification Predict\n",
    "## Introduction\n",
    "### Context\n",
    "Many companies are built around lessening oneâ€™s environmental impact or carbon footprint. They offer products and services that are environmentally friendly and sustainable, in line with their values and ideals. They would like to determine how people perceive climate change and whether or not they believe it is a real threat. This would add to their market research efforts in gauging how their product/service may be received.\n",
    "\n",
    "### The challenge\n",
    "\n",
    "With this context, EDSA is challenging you during the Classification Sprint with the task of creating a Machine Learning model that is able to classify whether or not a person believes in climate change, based on their novel tweet data.\n",
    "\n",
    "Providing an accurate and robust solution to this task gives companies access to a broad base of consumer sentiment, spanning multiple demographic and geographic categories - thus increasing their insights and informing future marketing strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332d23bd",
   "metadata": {},
   "source": [
    "### Hypothesis\n",
    "* Provide an interpretation of the target variable\n",
    "* List out the features on which our target variable might depend\n",
    "* Give a view about the problem based on domain knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6229b29e",
   "metadata": {},
   "source": [
    "### Data and Library Imports\n",
    "Now we will import the libraries required to perform:\n",
    "* language manipulation\n",
    "* data import, manipulation and visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9207d290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "\n",
    "# language manipulation\n",
    "import nltk # toolkit for language processing\n",
    "from nltk.corpus import stopwords # redundant words\n",
    "\n",
    "# Data manipulation and visualisation\n",
    "import numpy as np # mathematical processing\n",
    "import pandas as pd # data manipulation\n",
    "import seaborn as sns # data visualisation\n",
    "import matplotlib.pyplot as plt  # data visualisation\n",
    "%matplotlib inline\n",
    "\n",
    "import re # regular expressiosn\n",
    "\n",
    "# set plot style\n",
    "sns.set()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad8dd08",
   "metadata": {},
   "source": [
    "Next we will import the `test` and `train` data provided. Thereafter we will inspect the first 5 rows of the train data to get an understanding of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b035ab88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data importation\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e834ceff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562\n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 5 rows of train data\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5330d8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europe will now be looking to China to make su...</td>\n",
       "      <td>169760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Combine this with the polling of staffers re c...</td>\n",
       "      <td>35326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The scary, unimpeachable evidence that climate...</td>\n",
       "      <td>224985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Karoli @morgfair @OsborneInk @dailykos \\nPuti...</td>\n",
       "      <td>476263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @FakeWillMoore: 'Female orgasms cause globa...</td>\n",
       "      <td>872928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  tweetid\n",
       "0  Europe will now be looking to China to make su...   169760\n",
       "1  Combine this with the polling of staffers re c...    35326\n",
       "2  The scary, unimpeachable evidence that climate...   224985\n",
       "3  @Karoli @morgfair @OsborneInk @dailykos \\nPuti...   476263\n",
       "4  RT @FakeWillMoore: 'Female orgasms cause globa...   872928"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 5 rows of test data\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db3ace2",
   "metadata": {},
   "source": [
    "#### Data Description\n",
    "The collection of this data was funded by a Canada Foundation for Innovation JELF Grant to Chris Bauch, University of Waterloo. The dataset aggregates tweets pertaining to climate change collected between Apr 27, 2015 and Feb 21, 2018. In total, 43943 tweets were collected. Each tweet is labelled as one of the following classes:\n",
    "\n",
    "Class Description\n",
    "* 2 News: the tweet links to factual news about climate change\n",
    "* 1 Pro: the tweet supports the belief of man-made climate change\n",
    "* 0 Neutral: the tweet neither supports nor refutes the belief of man-made climate change\n",
    "* -1 Anti: the tweet does not believe in man-made climate change\n",
    "\n",
    "Variable definitions\n",
    "- sentiment: Sentiment of tweet\n",
    "- message: Tweet body\n",
    "- tweetid: Twitter unique id\n",
    "\n",
    "Let's confirm that the sentiment values conform to the description above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40ede91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the sentiment values\n",
    "list(train.sentiment.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77725a07",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acd411cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  0, -1], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbfa695a",
   "metadata": {},
   "source": [
    "##### Hypothesis validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a284c1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
